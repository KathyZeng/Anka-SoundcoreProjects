#!/usr/bin/env python3
"""
æ•°æ®ä¸Šä¼ é¡µé¢

å…è®¸ç”¨æˆ·ä¸Šä¼ Excelå·¥ä½œè´Ÿè½½æ•°æ®æ–‡ä»¶
æ˜¾ç¤ºä¸Šä¼ å†å²å’Œæ–‡ä»¶ç®¡ç†åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
from datetime import datetime
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.data_processor import WorkloadDataProcessor
from core.storage import StorageManager
from utils.config_loader import init_session_config
from utils.styles import apply_custom_styles, render_page_header
from utils.sidebar import render_compact_sidebar

st.set_page_config(page_title="æ•°æ®ä¸Šä¼ ", page_icon="ğŸ“Š", layout="wide")

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_custom_styles()

# åˆå§‹åŒ–é…ç½®
init_session_config()

# åˆå§‹åŒ–
storage = StorageManager()

# æ¸²æŸ“ç´§å‡‘ç‰ˆä¾§è¾¹æ 
render_compact_sidebar()

# æ¸²æŸ“é¡µé¢å¤´éƒ¨
render_page_header("æ•°æ®ä¸Šä¼ ", "ä¸Šä¼ æ‚¨çš„å·¥ä½œè´Ÿè½½Excelæ•°æ®æ–‡ä»¶è¿›è¡Œåˆ†æ", "ğŸ“Š")

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ğŸ“ ä¸Šä¼ æ–°æ–‡ä»¶")

    uploaded_file = st.file_uploader(
        "é€‰æ‹©Excelæ–‡ä»¶",
        type=['xlsx', 'xls'],
        help="è¯·ä¸Šä¼ åŒ…å«'é¢„ä¼°å·¥æ—¶'å·¥ä½œè¡¨çš„Excelæ–‡ä»¶"
    )

    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        st.success(f"âœ… æ–‡ä»¶å·²é€‰æ‹©: {uploaded_file.name}")
        st.write(f"æ–‡ä»¶å¤§å°: {uploaded_file.size / 1024:.2f} KB")

        # åŸºå‡†æ—¥æœŸé€‰æ‹©(ä»é…ç½®è¯»å–é»˜è®¤å€¼)
        config = st.session_state.get('config', {})
        use_today_default = config.get('base_date', {}).get('use_today_by_default', True)

        use_today = st.checkbox("ä½¿ç”¨ä»Šå¤©ä½œä¸ºåŸºå‡†æ—¥æœŸ", value=use_today_default)

        if use_today:
            base_date = datetime.now().strftime('%Y-%m-%d')
            st.info(f"ğŸ“… åŸºå‡†æ—¥æœŸ: {base_date}")
        else:
            base_date = st.date_input("é€‰æ‹©åŸºå‡†æ—¥æœŸ").strftime('%Y-%m-%d')

        # ä¸»è´£æˆå‘˜é€‰æ‹©
        st.markdown("---")
        st.subheader("ğŸ‘¤ ä¸»è´£æˆå‘˜è®¾ç½®")
        st.info("ğŸ’¡ ä¸»è´£æˆå‘˜éœ€è¦é¢å¤–æ—¶é—´è¿›è¡Œé¡¹ç›®å¯¹æ¥,ç³»ç»Ÿä¼šè‡ªåŠ¨ä¸ºå…¶å¢åŠ ä¸»è´£äº‹åŠ¡å·¥æ—¶")

        # è·å–é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤ä¸»è´£æˆå‘˜
        default_primary_members = st.session_state.config.get('primary_responsibility', {}).get('members', [])

        if default_primary_members:
            st.info(f"ğŸ“‹ é…ç½®æ–‡ä»¶ä¸­å·²è®¾ç½®é»˜è®¤ä¸»è´£æˆå‘˜({len(default_primary_members)}äºº): {', '.join(default_primary_members)}")

        # å…è®¸ç”¨æˆ·è‡ªå®šä¹‰ä¸»è´£æˆå‘˜
        customize_primary = st.checkbox("è‡ªå®šä¹‰ä¸»è´£æˆå‘˜(è¦†ç›–é»˜è®¤é…ç½®)", value=False)

        if customize_primary:
            try:
                # ä¸´æ—¶è¯»å–Excelè·å–æˆå‘˜åˆ—è¡¨
                temp_df = pd.read_excel(uploaded_file, sheet_name='é¢„ä¼°å·¥æ—¶')
                member_list = temp_df['æˆå‘˜'].tolist()

                # å¤šé€‰æ¡†é€‰æ‹©ä¸»è´£æˆå‘˜
                primary_members = st.multiselect(
                    "é€‰æ‹©ä¸»è´£æˆå‘˜(å¯å¤šé€‰)",
                    options=member_list,
                    default=default_primary_members if default_primary_members else [],
                    help="ä¸»è´£æˆå‘˜ä¼šé¢å¤–å¢åŠ ä¸»è´£äº‹åŠ¡å·¥æ—¶(é»˜è®¤50åˆ†é’Ÿ/å‘¨)"
                )

                if primary_members:
                    st.success(f"âœ… å·²é€‰æ‹© {len(primary_members)} åä¸»è´£æˆå‘˜: {', '.join(primary_members)}")
            except Exception as e:
                st.warning(f"âš ï¸ æ— æ³•è¯»å–æˆå‘˜åˆ—è¡¨: {str(e)}")
                primary_members = default_primary_members
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            primary_members = default_primary_members
            if primary_members:
                st.success(f"âœ… ä½¿ç”¨é»˜è®¤é…ç½®çš„ {len(primary_members)} åä¸»è´£æˆå‘˜")

        # å¤„ç†æŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
                try:
                    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
                    file_path = storage.save_uploaded_file(uploaded_file)
                    st.success(f"âœ… æ–‡ä»¶å·²ä¿å­˜: {os.path.basename(file_path)}")

                    # è¯»å–å¹¶å¤„ç†æ•°æ®
                    processor = WorkloadDataProcessor(st.session_state.config)

                    # è¯»å–Excel
                    df = processor.read_excel(file_path)
                    st.success(f"âœ… æˆåŠŸè¯»å–æ•°æ®: {len(df)} åæˆå‘˜")

                    # æ˜¾ç¤ºä¸»è´£ä¿¡æ¯
                    if primary_members:
                        st.info(f"ğŸ“Œ ä¸»è´£æˆå‘˜({len(primary_members)}äºº): {', '.join(primary_members)}")

                    # è®¡ç®—åˆ†æ
                    result_df, date_info = processor.calculate_workload(df, base_date, primary_members)

                    # è·å–ç»Ÿè®¡æ‘˜è¦
                    stats = processor.get_summary_stats(result_df)

                    # ä¿å­˜å¤„ç†åçš„æ•°æ®
                    identifier = date_info['base_date'].strftime('%Y%m%d')
                    processed_path = storage.save_processed_data(result_df, date_info, stats, identifier)

                    # ä¿å­˜åˆ°session state (ç¡®ä¿æ—¥æœŸå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²)
                    st.session_state.current_data = result_df

                    # è½¬æ¢æ—¥æœŸå¯¹è±¡ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿åºåˆ—åŒ–
                    serializable_date_info = {}
                    for k, v in date_info.items():
                        if hasattr(v, 'strftime'):
                            serializable_date_info[k] = v.strftime('%Y-%m-%d') if hasattr(v, 'strftime') else str(v)
                        else:
                            serializable_date_info[k] = v

                    st.session_state.current_analysis = {
                        'result_df': result_df,
                        'date_info': serializable_date_info,
                        'stats': stats,
                        'processed_path': processed_path
                    }

                    st.success("âœ… æ•°æ®å¤„ç†å®Œæˆ!")

                    # æ˜¾ç¤ºå¿«é€Ÿç»Ÿè®¡
                    st.markdown("### ğŸ“Š å¿«é€Ÿç»Ÿè®¡")
                    col_a, col_b, col_c, col_d = st.columns(4)

                    with col_a:
                        st.metric("æ€»äººæ•°", stats['total_members'])

                    with col_b:
                        st.metric("æœ¬å‘¨å¹³å‡é¥±å’Œåº¦", f"{stats['current_week']['avg_saturation']}%")

                    with col_c:
                        st.metric("ä¸‹å‘¨å¹³å‡é¥±å’Œåº¦", f"{stats['next_week']['avg_saturation']}%")

                    with col_d:
                        overloaded = stats['next_week']['overloaded']
                        st.metric("ä¸‹å‘¨è¶…è´Ÿè·", f"{overloaded} äºº", delta=None if overloaded == 0 else "âš ï¸")

                    # è®¾ç½®æ ‡å¿—è¡¨ç¤ºæ•°æ®å·²å¤„ç†å®Œæˆ
                    st.session_state.show_preview = True
                    st.session_state.show_analysis = True

                    st.markdown("---")

                    # æç¤ºç”¨æˆ·å‰å¾€å…¶ä»–é¡µé¢æŸ¥çœ‹è¯¦ç»†ç»“æœ
                    st.success("âœ… æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° session_stateï¼Œå¯ä»¥å‰å¾€å…¶ä»–é¡µé¢æŸ¥çœ‹è¯¦ç»†åˆ†æ")

                    st.info("""
                    ### ğŸ“‹ æ•°æ®ä¸Šä¼ å®Œæˆï¼è¯·é€šè¿‡å·¦ä¾§è¾¹æ å¯¼èˆªæŸ¥çœ‹ç»“æœ

                    **ä¸‹ä¸€æ­¥æ“ä½œ**:
                    1. ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ **æ•°æ®é¢„è§ˆ** æŸ¥çœ‹å®Œæ•´æ•°æ®è¡¨æ ¼
                    2. ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ **è´Ÿè½½åˆ†æ** æŸ¥çœ‹ä¸‰å‘¨å¯¹æ¯”å›¾è¡¨
                    3. ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ **è¶‹åŠ¿å¯¹æ¯”** æŸ¥çœ‹å†å²è¶‹åŠ¿åˆ†æ

                    **æ•°æ®å·²ä¿å­˜**: {0} åæˆå‘˜ï¼ŒåŸºå‡†æ—¥æœŸ {1}
                    """.format(stats['total_members'], serializable_date_info['base_date']))

                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                    with st.expander("ğŸ”§ è°ƒè¯•ä¿¡æ¯ (ç‚¹å‡»å±•å¼€)"):
                        st.write("Session State Keys:", list(st.session_state.keys()))
                        st.write("current_analysis å­˜åœ¨:", 'current_analysis' in st.session_state)
                        if 'current_analysis' in st.session_state:
                            st.write("result_df shape:", st.session_state.current_analysis['result_df'].shape)
                            st.write("date_info keys:", list(st.session_state.current_analysis['date_info'].keys()))
                            st.write("stats keys:", list(st.session_state.current_analysis['stats'].keys()))

                except Exception as e:
                    st.error(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())

with col2:
    st.subheader("ğŸ“‹ æ•°æ®æ ¼å¼è¦æ±‚")

    with st.expander("ç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…"):
        st.markdown("""
        **Excelæ–‡ä»¶è¦æ±‚:**

        1. **Sheetåç§°**: "é¢„ä¼°å·¥æ—¶"
        2. **ç¬¬ä¸€åˆ—**: æˆå‘˜åç§°
        3. **å…¶ä»–åˆ—**: æ—¥æœŸ(æ ¼å¼: YYYY-MM-DD)

        **ç¤ºä¾‹:**

        | æˆå‘˜ | 2025-11-17 | 2025-11-18 | 2025-11-19 |
        |------|-----------|-----------|-----------|
        | å¼ ä¸‰ | 8 | 8 | 0 |
        | æå›› | 8 | 8 | 8 |

        **æ³¨æ„äº‹é¡¹:**
        - å·¥æ—¶å•ä½ä¸ºå°æ—¶
        - æ—¥æœŸå¿…é¡»æ˜¯YYYY-MM-DDæ ¼å¼
        - ç¡®ä¿æ•°æ®å®Œæ•´æ— ç¼ºå¤±
        """)

st.markdown("---")

# ä¸Šä¼ å†å²
st.subheader("ğŸ“œ ä¸Šä¼ å†å²")

# æ·»åŠ æ¸…ç©ºæ‰€æœ‰å†å²çš„æŒ‰é’®
col_history_title, col_history_clear = st.columns([4, 1])

with col_history_clear:
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰", type="secondary", use_container_width=True):
        # åˆ é™¤æ‰€æœ‰ä¸Šä¼ çš„æ–‡ä»¶
        if os.path.exists(storage.uploads_dir):
            for filename in os.listdir(storage.uploads_dir):
                file_path = os.path.join(storage.uploads_dir, filename)
                if os.path.isfile(file_path):
                    storage.delete_file(file_path)

        # åˆ é™¤æ‰€æœ‰å¤„ç†åçš„æ–‡ä»¶
        if os.path.exists(storage.processed_dir):
            for filename in os.listdir(storage.processed_dir):
                file_path = os.path.join(storage.processed_dir, filename)
                if os.path.isfile(file_path):
                    storage.delete_file(file_path)

        # æ¸…ç©ºå†å²è®°å½•
        if os.path.exists(storage.history_file):
            os.remove(storage.history_file)

        st.success("âœ… å·²æ¸…ç©ºæ‰€æœ‰å†å²è®°å½•å’Œæ–‡ä»¶")
        st.rerun()

history = storage.get_upload_history(limit=10)

if history:
    for i, record in enumerate(history):
        with st.expander(f"ğŸ“„ {record['original_name']} - {record['timestamp'][:19].replace('T', ' ')}"):
            col_a, col_b, col_c, col_d = st.columns([2, 1, 1, 1])

            with col_a:
                st.write(f"**åŸå§‹æ–‡ä»¶å**: {record['original_name']}")
                st.write(f"**ä¿å­˜æ–‡ä»¶å**: {record['filename']}")
                st.write(f"**æ–‡ä»¶å¤§å°**: {record['size'] / 1024:.2f} KB")

            with col_b:
                if os.path.exists(record['file_path']):
                    with open(record['file_path'], 'rb') as f:
                        st.download_button(
                            "ğŸ“¥ ä¸‹è½½",
                            f,
                            file_name=record['original_name'],
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key=f"download_{i}"
                        )
                else:
                    st.warning("æ–‡ä»¶ä¸å­˜åœ¨")

            with col_c:
                # é‡æ–°åˆ†ææŒ‰é’®
                if os.path.exists(record['file_path']):
                    if st.button("ğŸ“Š é‡æ–°åˆ†æ", key=f"reanalyze_{i}", type="primary"):
                        with st.spinner("æ­£åœ¨é‡æ–°å¤„ç†æ•°æ®..."):
                            try:
                                # è·å–é…ç½®ä¸­çš„é»˜è®¤ä¸»è´£æˆå‘˜
                                default_primary_members = st.session_state.config.get('primary_responsibility', {}).get('members', [])

                                # ä½¿ç”¨ä»Šå¤©ä½œä¸ºåŸºå‡†æ—¥æœŸ
                                base_date = datetime.now().strftime('%Y-%m-%d')

                                # è¯»å–å¹¶å¤„ç†æ•°æ®
                                processor = WorkloadDataProcessor(st.session_state.config)
                                df = processor.read_excel(record['file_path'])

                                # è®¡ç®—åˆ†æ
                                result_df, date_info = processor.calculate_workload(df, base_date, default_primary_members)

                                # è·å–ç»Ÿè®¡æ‘˜è¦
                                stats = processor.get_summary_stats(result_df)

                                # ä¿å­˜å¤„ç†åçš„æ•°æ®
                                identifier = date_info['base_date'].strftime('%Y%m%d')
                                processed_path = storage.save_processed_data(result_df, date_info, stats, identifier)

                                # ä¿å­˜åˆ°session state
                                st.session_state.current_data = result_df

                                # è½¬æ¢æ—¥æœŸå¯¹è±¡ä¸ºå­—ç¬¦ä¸²
                                serializable_date_info = {}
                                for k, v in date_info.items():
                                    if hasattr(v, 'strftime'):
                                        serializable_date_info[k] = v.strftime('%Y-%m-%d')
                                    else:
                                        serializable_date_info[k] = v

                                st.session_state.current_analysis = {
                                    'result_df': result_df,
                                    'date_info': serializable_date_info,
                                    'stats': stats,
                                    'processed_path': processed_path
                                }

                                st.session_state.show_preview = True
                                st.session_state.show_analysis = True

                                st.success(f"âœ… é‡æ–°åˆ†æå®Œæˆï¼æˆå‘˜æ•°: {stats['total_members']}, åŸºå‡†æ—¥æœŸ: {serializable_date_info['base_date']}")

                                # æ˜¾ç¤ºå¯¼èˆªæç¤º
                                st.info("""
                                ### ğŸ“‹ æ•°æ®å·²æ›´æ–°ï¼è¯·é€šè¿‡å·¦ä¾§è¾¹æ å¯¼èˆªæŸ¥çœ‹ç»“æœ

                                **ä¸‹ä¸€æ­¥æ“ä½œ**:
                                1. ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ **æ•°æ®é¢„è§ˆ** æŸ¥çœ‹å®Œæ•´æ•°æ®è¡¨æ ¼
                                2. ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ **è´Ÿè½½åˆ†æ** æŸ¥çœ‹ä¸‰å‘¨å¯¹æ¯”å›¾è¡¨
                                3. ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ **è¶‹åŠ¿å¯¹æ¯”** æŸ¥çœ‹å†å²è¶‹åŠ¿åˆ†æ
                                """)

                            except Exception as e:
                                st.error(f"âŒ é‡æ–°åˆ†æå¤±è´¥: {str(e)}")
                                import traceback
                                st.code(traceback.format_exc())

            with col_d:
                if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{i}", type="secondary"):
                    try:
                        # 1. åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶
                        storage.delete_file(record['file_path'])

                        # 2. åˆ é™¤å¯¹åº”çš„å¤„ç†åæ•°æ®
                        # æŸ¥æ‰¾å¯¹åº”çš„ processed æ–‡ä»¶ï¼ˆåŸºäºæ–‡ä»¶åæ—¶é—´æˆ³ï¼‰
                        timestamp = record['filename'].split('_')[0]  # æå–æ—¶é—´æˆ³
                        processed_dir = os.path.join(storage.processed_dir)
                        if os.path.exists(processed_dir):
                            for filename in os.listdir(processed_dir):
                                if filename.startswith(timestamp):
                                    processed_path = os.path.join(processed_dir, filename)
                                    storage.delete_file(processed_path)

                        # 3. ä»å†å²è®°å½•ä¸­ç§»é™¤
                        storage.remove_from_history(record['file_path'])

                        st.success("âœ… å·²åˆ é™¤æ–‡ä»¶ã€ç›¸å…³æ•°æ®åŠå†å²è®°å½•")
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ åˆ é™¤å¤±è´¥: {str(e)}")
else:
    st.info("ğŸ“­ æš‚æ— ä¸Šä¼ å†å²")

# åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.caption("ğŸ’¡ æç¤º: ä¸Šä¼ çš„æ–‡ä»¶ä¼šè‡ªåŠ¨ä¿å­˜åœ¨ data/uploads ç›®å½•ä¸‹")
